{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c430c105-3eb0-443b-994d-bf0808be61a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: fichier absent /home/amina/DTE/jne_project/refined/sensors/2025-03/zone_101_sensors_refined.csv\n",
      "WARN: fichier absent /home/amina/DTE/jne_project/refined/sensors/2025-03/zone_101_sensors_refined.csv\n",
      "WARN: fichier absent /home/amina/DTE/jne_project/refined/sensors/2025-03/zone_101_sensors_refined.csv\n",
      "minio: s3://model/jne_project/model/2025-03/training_room_model_dataset.parquet\n",
      "OK: /home/amina/DTE/jne_project/model/2025-03/training_room_model.ttl /home/amina/DTE/jne_project/model/2025-03/training_room_model_dataset.csv /home/amina/DTE/jne_project/model/2025-03/training_room_model_dataset.parquet /home/amina/DTE/jne_project/model/meta/2025-03/model_manifest.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# build_model_from_ttl_minio.py — dérive le dataset tabulaire depuis training_room_semantic_full.ttl\n",
    "# Sorties locales: ~/DTE/jne_project/model/{YYYY-MM}/ (ttl + csv + parquet + manifest)\n",
    "# Upload: s3://model/jne_project/model/{YYYY-MM}/...\n",
    "\n",
    "import os, sys, json, argparse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF\n",
    "\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/1.1/Brick#\")\n",
    "BF    = Namespace(\"https://brickschema.org/schema/BrickFrame#\")\n",
    "EX    = Namespace(\"http://example.org/training#\")\n",
    "\n",
    "# ---------- MinIO ----------\n",
    "def s3_client(endpoint, access, secret, secure):\n",
    "    import boto3\n",
    "    from botocore.config import Config\n",
    "    return boto3.client(\"s3\", endpoint_url=endpoint,\n",
    "        aws_access_key_id=access, aws_secret_access_key=secret,\n",
    "        use_ssl=bool(secure), verify=bool(secure),\n",
    "        region_name=\"us-east-1\", config=Config(signature_version=\"s3v4\"))\n",
    "\n",
    "def ensure_bucket(s3, bucket):\n",
    "    import botocore\n",
    "    try: s3.head_bucket(Bucket=bucket)\n",
    "    except botocore.exceptions.ClientError: s3.create_bucket(Bucket=bucket)\n",
    "\n",
    "def s3_upload(s3, bucket, p:Path, key:str): s3.upload_file(str(p), bucket, key)\n",
    "\n",
    "# ---------- TTL → mapping (csv_uri, column) + BIM ----------\n",
    "def parse_ttl(ttl_path: Path):\n",
    "    g = Graph().parse(str(ttl_path), format=\"turtle\")\n",
    "    mapping = []  # [{sensor, csv_uri, column}]\n",
    "    for s, _, o in g.triples((None, BF.hasTimeseriesId, None)):\n",
    "        tsid = str(o)\n",
    "        if \"::\" in tsid:\n",
    "            uri, col = tsid.split(\"::\", 1)\n",
    "            mapping.append({\"sensor\": str(s), \"csv_uri\": uri, \"column\": col})\n",
    "    # BIM: toutes les propriétés EX:* de la pièce\n",
    "    bim = {}\n",
    "    room = EX[\"Room_101\"]\n",
    "    if (room, RDF.type, None) not in g:\n",
    "        rooms = list(g.subjects(RDF.type, BRICK.Room))\n",
    "        if rooms: room = rooms[0]\n",
    "    for p, o in g.predicate_objects(room):\n",
    "        sp = str(p)\n",
    "        if sp.startswith(str(EX)):\n",
    "            key = \"BIM_\" + sp.split(\"#\")[-1]\n",
    "            val = getattr(o, \"toPython\", lambda: o)()\n",
    "            bim[key] = str(val)\n",
    "    return mapping, bim\n",
    "\n",
    "# ---------- Chargement et fusion ----------\n",
    "def build_table(mapping, refined_root=\"~/DTE/jne_project/refined\"):\n",
    "    cache = {}\n",
    "    dfs = []\n",
    "    for m in mapping:\n",
    "        local = Path(m[\"csv_uri\"].replace(\"minio://refined\", refined_root)).expanduser().resolve()\n",
    "        if not local.exists():\n",
    "            print(f\"WARN: fichier absent {local}\")\n",
    "            continue\n",
    "        if local not in cache:\n",
    "            cache[local] = pd.read_csv(local)\n",
    "        df = cache[local]\n",
    "        col = m[\"column\"]\n",
    "        if \"ts\" not in df.columns or col not in df.columns:\n",
    "            print(f\"WARN: colonnes manquantes dans {local} ({col})\")\n",
    "            continue\n",
    "        # nom de colonne lisible = suffixe de l'URI du capteur\n",
    "        cname = m[\"sensor\"].split(\"#\")[-1]\n",
    "        dfs.append(df[[\"ts\", col]].rename(columns={col: cname}))\n",
    "    if not dfs:\n",
    "        return None\n",
    "    out = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        out = out.merge(d, on=\"ts\", how=\"outer\")\n",
    "    # tri + ISO\n",
    "    out = out.sort_values(\"ts\")\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--month\", type=str, default=\"2025-03\")\n",
    "    ap.add_argument(\"--ttl_full\", type=str, default=\"~/DTE/jne_project/semantic/{month}/training_room_semantic_full.ttl\")\n",
    "    ap.add_argument(\"--model_base\", type=str, default=\"~/DTE/jne_project/model\")\n",
    "    # MinIO model\n",
    "    ap.add_argument(\"--endpoint\", type=str, default=os.environ.get(\"MINIO_ENDPOINT\",\"http://192.168.0.173:9000\"))\n",
    "    ap.add_argument(\"--access\",   type=str, default=os.environ.get(\"MINIO_ROOT_USER\",\"minioadmin\"))\n",
    "    ap.add_argument(\"--secret\",   type=str, default=os.environ.get(\"MINIO_ROOT_PASSWORD\",\"minioadmin\"))\n",
    "    ap.add_argument(\"--bucket\",   type=str, default=\"model\")\n",
    "    ap.add_argument(\"--prefix\",   type=str, default=\"jne_project/model\")\n",
    "    ap.add_argument(\"--secure\",   action=\"store_true\")\n",
    "    ap.add_argument(\"--no-upload\", action=\"store_true\")\n",
    "    args,_ = ap.parse_known_args()\n",
    "\n",
    "    month = args.month\n",
    "    ttl_path = Path(args.ttl_full.format(month=month)).expanduser().resolve()\n",
    "\n",
    "    model_dir = Path(args.model_base).expanduser().resolve() / month\n",
    "    meta_dir  = Path(args.model_base).expanduser().resolve() / \"meta\" / month\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    meta_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    mapping, bim = parse_ttl(ttl_path)\n",
    "    df = build_table(mapping)\n",
    "    if df is None:\n",
    "        print(\"ERREUR: aucune série chargée depuis le TTL\"); sys.exit(1)\n",
    "\n",
    "    # Ajouter BIM (constantes)\n",
    "    for k, v in bim.items():\n",
    "        df[k] = v\n",
    "\n",
    "    # Sauvegardes locales\n",
    "    out_ttl_copy = model_dir / \"training_room_model.ttl\"\n",
    "    out_csv      = model_dir / \"training_room_model_dataset.csv\"\n",
    "    out_parquet  = model_dir / \"training_room_model_dataset.parquet\"\n",
    "\n",
    "    # copier le TTL complet tel quel\n",
    "    out_ttl_copy.write_text(Path(ttl_path).read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    df.to_parquet(out_parquet, index=False)\n",
    "\n",
    "    manifest = {\n",
    "        \"version\":\"1.0\",\n",
    "        \"month\": month,\n",
    "        \"ttl_input\": str(ttl_path),\n",
    "        \"outputs\": {\"ttl\": str(out_ttl_copy), \"csv\": str(out_csv), \"parquet\": str(out_parquet)},\n",
    "        \"rows\": int(len(df)), \"columns\": list(df.columns),\n",
    "        \"mapping_count\": len(mapping),\n",
    "        \"bim_keys\": list(bim.keys())\n",
    "    }\n",
    "    man_path = meta_dir / \"model_manifest.json\"\n",
    "    man_path.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Upload MinIO\n",
    "    if not args.no_upload:\n",
    "        try:\n",
    "            s3 = s3_client(args.endpoint, args.access, args.secret, args.secure)\n",
    "            ensure_bucket(s3, args.bucket)\n",
    "            root = args.prefix.strip(\"/\")\n",
    "            s3_upload(s3, args.bucket, out_ttl_copy, f\"{root}/{month}/training_room_model.ttl\")\n",
    "            s3_upload(s3, args.bucket, out_csv,      f\"{root}/{month}/training_room_model_dataset.csv\")\n",
    "            s3_upload(s3, args.bucket, out_parquet,  f\"{root}/{month}/training_room_model_dataset.parquet\")\n",
    "            s3_upload(s3, args.bucket, man_path,     f\"{root}/meta/{month}/model_manifest.json\")\n",
    "            print(\"minio:\", f\"s3://{args.bucket}/{root}/{month}/training_room_model_dataset.parquet\")\n",
    "        except Exception as e:\n",
    "            print(\"ERREUR MinIO:\", e); sys.exit(3)\n",
    "\n",
    "    print(\"OK:\", out_ttl_copy, out_csv, out_parquet, man_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8374f05b-0b0f-4469-a5bc-447f4ac8d950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: fichier absent /home/amina/DTE/jne_project/refined/sensors/2025-03/zone_101_sensors_refined.csv\n",
      "WARN: fichier absent /home/amina/DTE/jne_project/refined/sensors/2025-03/zone_101_sensors_refined.csv\n",
      "WARN: fichier absent /home/amina/DTE/jne_project/refined/sensors/2025-03/zone_101_sensors_refined.csv\n",
      "minio: s3://model/jne_project/model/2025-03/training_room_model_dataset.parquet\n",
      "OK: /home/amina/DTE/jne_project/model/2025-03/training_room_model.ttl /home/amina/DTE/jne_project/model/2025-03/training_room_model_dataset.csv /home/amina/DTE/jne_project/model/2025-03/training_room_model_dataset.parquet /home/amina/DTE/jne_project/model/meta/2025-03/model_manifest.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# build_model_from_ttl_minio.py — dérive le dataset tabulaire depuis training_room_semantic_full.ttl\n",
    "# Sorties locales: ~/DTE/jne_project/model/{YYYY-MM}/ (ttl + csv + parquet + manifest)\n",
    "# Upload: s3://model/jne_project/model/{YYYY-MM}/...\n",
    "\n",
    "import os, sys, json, argparse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF\n",
    "\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/1.1/Brick#\")\n",
    "BF    = Namespace(\"https://brickschema.org/schema/BrickFrame#\")\n",
    "EX    = Namespace(\"http://example.org/training#\")\n",
    "\n",
    "# ---------- MinIO ----------\n",
    "def s3_client(endpoint, access, secret, secure):\n",
    "    import boto3\n",
    "    from botocore.config import Config\n",
    "    return boto3.client(\"s3\", endpoint_url=endpoint,\n",
    "        aws_access_key_id=access, aws_secret_access_key=secret,\n",
    "        use_ssl=bool(secure), verify=bool(secure),\n",
    "        region_name=\"us-east-1\", config=Config(signature_version=\"s3v4\"))\n",
    "\n",
    "def ensure_bucket(s3, bucket):\n",
    "    import botocore\n",
    "    try: s3.head_bucket(Bucket=bucket)\n",
    "    except botocore.exceptions.ClientError: s3.create_bucket(Bucket=bucket)\n",
    "\n",
    "def s3_upload(s3, bucket, p:Path, key:str): s3.upload_file(str(p), bucket, key)\n",
    "\n",
    "# ---------- TTL → mapping (csv_uri, column) + BIM ----------\n",
    "def parse_ttl(ttl_path: Path):\n",
    "    g = Graph().parse(str(ttl_path), format=\"turtle\")\n",
    "    mapping = []  # [{sensor, csv_uri, column}]\n",
    "    for s, _, o in g.triples((None, BF.hasTimeseriesId, None)):\n",
    "        tsid = str(o)\n",
    "        if \"::\" in tsid:\n",
    "            uri, col = tsid.split(\"::\", 1)\n",
    "            mapping.append({\"sensor\": str(s), \"csv_uri\": uri, \"column\": col})\n",
    "    # BIM: toutes les propriétés EX:* de la pièce\n",
    "    bim = {}\n",
    "    room = EX[\"Room_101\"]\n",
    "    if (room, RDF.type, None) not in g:\n",
    "        rooms = list(g.subjects(RDF.type, BRICK.Room))\n",
    "        if rooms: room = rooms[0]\n",
    "    for p, o in g.predicate_objects(room):\n",
    "        sp = str(p)\n",
    "        if sp.startswith(str(EX)):\n",
    "            key = \"BIM_\" + sp.split(\"#\")[-1]\n",
    "            val = getattr(o, \"toPython\", lambda: o)()\n",
    "            bim[key] = str(val)\n",
    "    return mapping, bim\n",
    "\n",
    "# ---------- Chargement et fusion ----------\n",
    "def build_table(mapping, refined_root=\"~/DTE/jne_project/refined\"):\n",
    "    cache = {}\n",
    "    dfs = []\n",
    "    for m in mapping:\n",
    "        local = Path(m[\"csv_uri\"].replace(\"minio://refined\", refined_root)).expanduser().resolve()\n",
    "        if not local.exists():\n",
    "            print(f\"WARN: fichier absent {local}\")\n",
    "            continue\n",
    "        if local not in cache:\n",
    "            cache[local] = pd.read_csv(local)\n",
    "        df = cache[local]\n",
    "        col = m[\"column\"]\n",
    "        if \"ts\" not in df.columns or col not in df.columns:\n",
    "            print(f\"WARN: colonnes manquantes dans {local} ({col})\")\n",
    "            continue\n",
    "        # nom de colonne lisible = suffixe de l'URI du capteur\n",
    "        cname = m[\"sensor\"].split(\"#\")[-1]\n",
    "        dfs.append(df[[\"ts\", col]].rename(columns={col: cname}))\n",
    "    if not dfs:\n",
    "        return None\n",
    "    out = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        out = out.merge(d, on=\"ts\", how=\"outer\")\n",
    "    # tri + ISO\n",
    "    out = out.sort_values(\"ts\")\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--month\", type=str, default=\"2025-03\")\n",
    "    ap.add_argument(\"--ttl_full\", type=str, default=\"~/DTE/jne_project/semantic/{month}/training_room_semantic_full.ttl\")\n",
    "    ap.add_argument(\"--model_base\", type=str, default=\"~/DTE/jne_project/model\")\n",
    "    # MinIO model\n",
    "    ap.add_argument(\"--endpoint\", type=str, default=os.environ.get(\"MINIO_ENDPOINT\",\"http://192.168.0.173:9000\"))\n",
    "    ap.add_argument(\"--access\",   type=str, default=os.environ.get(\"MINIO_ROOT_USER\",\"minioadmin\"))\n",
    "    ap.add_argument(\"--secret\",   type=str, default=os.environ.get(\"MINIO_ROOT_PASSWORD\",\"minioadmin\"))\n",
    "    ap.add_argument(\"--bucket\",   type=str, default=\"model\")\n",
    "    ap.add_argument(\"--prefix\",   type=str, default=\"jne_project/model\")\n",
    "    ap.add_argument(\"--secure\",   action=\"store_true\")\n",
    "    ap.add_argument(\"--no-upload\", action=\"store_true\")\n",
    "    args,_ = ap.parse_known_args()\n",
    "\n",
    "    month = args.month\n",
    "    ttl_path = Path(args.ttl_full.format(month=month)).expanduser().resolve()\n",
    "\n",
    "    model_dir = Path(args.model_base).expanduser().resolve() / month\n",
    "    meta_dir  = Path(args.model_base).expanduser().resolve() / \"meta\" / month\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    meta_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    mapping, bim = parse_ttl(ttl_path)\n",
    "    df = build_table(mapping)\n",
    "    if df is None:\n",
    "        print(\"ERREUR: aucune série chargée depuis le TTL\"); sys.exit(1)\n",
    "\n",
    "    # Ajouter BIM (constantes)\n",
    "    for k, v in bim.items():\n",
    "        df[k] = v\n",
    "\n",
    "    # Sauvegardes locales\n",
    "    out_ttl_copy = model_dir / \"training_room_model.ttl\"\n",
    "    out_csv      = model_dir / \"training_room_model_dataset.csv\"\n",
    "    out_parquet  = model_dir / \"training_room_model_dataset.parquet\"\n",
    "\n",
    "    # copier le TTL complet tel quel\n",
    "    out_ttl_copy.write_text(Path(ttl_path).read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    df.to_parquet(out_parquet, index=False)\n",
    "\n",
    "    manifest = {\n",
    "        \"version\":\"1.0\",\n",
    "        \"month\": month,\n",
    "        \"ttl_input\": str(ttl_path),\n",
    "        \"outputs\": {\"ttl\": str(out_ttl_copy), \"csv\": str(out_csv), \"parquet\": str(out_parquet)},\n",
    "        \"rows\": int(len(df)), \"columns\": list(df.columns),\n",
    "        \"mapping_count\": len(mapping),\n",
    "        \"bim_keys\": list(bim.keys())\n",
    "    }\n",
    "    man_path = meta_dir / \"model_manifest.json\"\n",
    "    man_path.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Upload MinIO\n",
    "    if not args.no_upload:\n",
    "        try:\n",
    "            s3 = s3_client(args.endpoint, args.access, args.secret, args.secure)\n",
    "            ensure_bucket(s3, args.bucket)\n",
    "            root = args.prefix.strip(\"/\")\n",
    "            s3_upload(s3, args.bucket, out_ttl_copy, f\"{root}/{month}/training_room_model.ttl\")\n",
    "            s3_upload(s3, args.bucket, out_csv,      f\"{root}/{month}/training_room_model_dataset.csv\")\n",
    "            s3_upload(s3, args.bucket, out_parquet,  f\"{root}/{month}/training_room_model_dataset.parquet\")\n",
    "            s3_upload(s3, args.bucket, man_path,     f\"{root}/meta/{month}/model_manifest.json\")\n",
    "            print(\"minio:\", f\"s3://{args.bucket}/{root}/{month}/training_room_model_dataset.parquet\")\n",
    "        except Exception as e:\n",
    "            print(\"ERREUR MinIO:\", e); sys.exit(3)\n",
    "\n",
    "    print(\"OK:\", out_ttl_copy, out_csv, out_parquet, man_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f23f0d-0c3e-4ec6-8855-1371cc7be8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK → /home/amina/DTE/jne_project/semantic/2025-03/training_room_graph_readable.svg\n",
      "OK → /home/amina/DTE/jne_project/semantic/2025-03/training_room_graph_readable.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# visualize_semantic_compact.py — Graphe lisible Brick+BIM+Météo+IoT (A4, SVG+PNG)\n",
    "\n",
    "from pathlib import Path\n",
    "import re, argparse\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import pygraphviz as pgv\n",
    "\n",
    "BRICK = rdflib.Namespace(\"https://brickschema.org/schema/1.1/Brick#\")\n",
    "BF    = rdflib.Namespace(\"https://brickschema.org/schema/BrickFrame#\")\n",
    "EX    = rdflib.Namespace(\"http://example.org/training#\")\n",
    "\n",
    "# ---------- utils ----------\n",
    "def short(u):\n",
    "    s = str(u)\n",
    "    return s.split(\"#\")[-1] if \"#\" in s else s.rsplit(\"/\",1)[-1]\n",
    "\n",
    "def clean_label(s):\n",
    "    return re.sub(r\"_+\", \" \", str(s)).strip()\n",
    "\n",
    "def last_and_stats(df, col):\n",
    "    if col not in df.columns:\n",
    "        return None, None, None, None\n",
    "    s = df[col]\n",
    "    if s.dtype == bool:\n",
    "        s = s.astype(int)\n",
    "    cat_map = {\"low\":0.25,\"normal\":0.5,\"med\":0.75,\"medium\":0.75,\"high\":1.0,\n",
    "               \"Low\":0.25,\"Normal\":0.5,\"Med\":0.75,\"Medium\":0.75,\"High\":1.0,\n",
    "               \"OFF\":0,\"ON\":1,\"Off\":0,\"On\":1, False:0, True:1}\n",
    "    if s.dtype == object:\n",
    "        s = s.map(lambda x: cat_map.get(x, x))\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return None, None, None, None\n",
    "    tail = s.tail(96)  # 24 h @ 15 min\n",
    "    return float(s.iloc[-1]), float(tail.min()), float(tail.max()), float(tail.mean())\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--ttl\", default=\"~/DTE/jne_project/semantic/2025-03/training_room_semantic_full.ttl\")\n",
    "    ap.add_argument(\"--csv\", default=\"~/DTE/jne_project/model/2025-03/training_room_model_dataset.csv\")\n",
    "    ap.add_argument(\"--out\", default=\"~/DTE/jne_project/semantic/2025-03/training_room_graph_readable\")  # sans extension\n",
    "    args,_ = ap.parse_known_args()\n",
    "\n",
    "    ttl_path = Path(args.ttl).expanduser()\n",
    "    csv_path = Path(args.csv).expanduser()\n",
    "    out_base = Path(args.out).expanduser()\n",
    "    out_base.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    g = rdflib.Graph().parse(str(ttl_path), format=\"turtle\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ----- Graphviz compact A4 paysage -----\n",
    "    G = pgv.AGraph(\n",
    "        directed=True, strict=False,\n",
    "        rankdir=\"LR\", splines=\"spline\",\n",
    "        overlap=\"false\", concentrate=\"true\",\n",
    "        nodesep=\"0.45\", ranksep=\"0.7\"\n",
    "    )\n",
    "    G.graph_attr.update(\n",
    "        fontname=\"DejaVu Sans\", fontsize=\"12\",\n",
    "        outputorder=\"edgesfirst\",\n",
    "        size=\"20,12!\", ratio=\"compress\",\n",
    "        center=\"true\", margin=\"0.1\", pad=\"0.1\",\n",
    "        bgcolor=\"white\", dpi=\"300\"   # <- résolution PNG\n",
    "    )\n",
    "\n",
    "    STYLES = {\n",
    "        \"hier\":   dict(shape=\"box\",     style=\"filled,rounded\", fillcolor=\"#b3cde0\"),\n",
    "        \"room\":   dict(shape=\"ellipse\", style=\"filled\",         fillcolor=\"#ccebc5\"),\n",
    "        \"env\":    dict(shape=\"box\",     style=\"filled,rounded\", fillcolor=\"#decbe4\"),\n",
    "        \"prop\":   dict(shape=\"ellipse\", style=\"filled\",         fillcolor=\"#fed9a6\"),\n",
    "        \"system\": dict(shape=\"box\",     style=\"filled,rounded\", fillcolor=\"#fff2a8\"),\n",
    "        \"equip\":  dict(shape=\"box\",     style=\"filled,rounded\", fillcolor=\"#aed6f1\"),\n",
    "        \"sensor\": dict(shape=\"ellipse\", style=\"filled\",         fillcolor=\"#f7b7b2\"),\n",
    "        \"setpt\":  dict(shape=\"note\",    style=\"filled\",         fillcolor=\"#d9d9d9\"),\n",
    "        \"obs\":    dict(shape=\"ellipse\", style=\"filled\",         fillcolor=\"#e0e0e0\"),\n",
    "        \"ts\":     dict(shape=\"box\",     style=\"filled,rounded\", fillcolor=\"#ffe4c4\"),\n",
    "        \"virt\":   dict(shape=\"ellipse\", style=\"filled\",         fillcolor=\"#d0f0c0\"),\n",
    "    }\n",
    "\n",
    "    def N(name, label, key):\n",
    "        G.add_node(name, label=label, fontname=\"DejaVu Sans\", **STYLES[key])\n",
    "    def E(a,b,label,color=\"#666666\"):\n",
    "        G.add_edge(a,b, label=label, fontsize=\"10\", color=color, fontcolor=color)\n",
    "\n",
    "    # clusters\n",
    "    c_build = G.add_subgraph(name=\"cluster_build\", label=\"Building hierarchy\", color=\"#7fb3d5\")\n",
    "    c_env   = G.add_subgraph(name=\"cluster_env\",   label=\"Envelope\",           color=\"#bb8fce\")\n",
    "    c_sys   = G.add_subgraph(name=\"cluster_sys\",   label=\"Systems\",            color=\"#f7dc6f\")\n",
    "    c_eq    = G.add_subgraph(name=\"cluster_eq\",    label=\"Equipment\",          color=\"#85c1e9\")\n",
    "    c_sens  = G.add_subgraph(name=\"cluster_sens\",  label=\"Sensors\",            color=\"#f5b7b1\")\n",
    "    c_obs   = G.add_subgraph(name=\"cluster_obs\",   label=\"Observations\",       color=\"#d5dbdb\")\n",
    "    c_ts    = G.add_subgraph(name=\"cluster_ts\",    label=\"Time Series\",        color=\"#f8c471\")\n",
    "    c_leg   = G.add_subgraph(name=\"cluster_leg\",   label=\"Legend\",             color=\"#bfc9ca\")\n",
    "\n",
    "    for lbl,key in [(\"Building hierarchy\",\"hier\"),(\"Training Room\",\"room\"),(\"Envelope\",\"env\"),\n",
    "                    (\"Properties\",\"prop\"),(\"Systems\",\"system\"),(\"Equipment\",\"equip\"),\n",
    "                    (\"Sensors\",\"sensor\"),(\"Setpoints\",\"setpt\"),(\"Observations\",\"obs\"),\n",
    "                    (\"Time Series\",\"ts\"),(\"Virtual Weather Sensors\",\"virt\")]:\n",
    "        c_leg.add_node(f\"leg_{key}\", label=lbl, **STYLES[key])\n",
    "\n",
    "    # bâtiment\n",
    "    N(\"Site\", \"Site: ENSMR Rabat\", \"hier\");     c_build.add_node(\"Site\")\n",
    "    N(\"Building\", \"Building\", \"hier\");          c_build.add_node(\"Building\")\n",
    "    N(\"Floor\", \"Floor: Ground\", \"hier\");        c_build.add_node(\"Floor\")\n",
    "    N(\"Room\", \"Training Room\", \"room\");         c_build.add_node(\"Room\")\n",
    "    E(\"Site\",\"Building\",\"hasPart\"); E(\"Building\",\"Floor\",\"hasPart\"); E(\"Floor\",\"Room\",\"hasPart\")\n",
    "\n",
    "    # enveloppe\n",
    "    for w in g.subjects(None, EX.Wall):\n",
    "        wid = short(w)\n",
    "        N(wid, clean_label(wid), \"env\"); c_env.add_node(wid); E(\"Room\", wid, \"hasPart\")\n",
    "        for p in [EX.r_value_m2K_W, EX.u_value_W_m2K, EX.thickness_m, EX.orientation]:\n",
    "            for _,_,o in g.triples((w,p,None)):\n",
    "                pid = f\"{wid}_{short(p)}\"\n",
    "                N(pid, f\"{short(p)}: {o}\", \"prop\"); c_obs.add_node(pid); E(wid, pid, \"hasProperty\",\"#999999\")\n",
    "\n",
    "    # systèmes\n",
    "    systems = [(EX[\"HVAC_System\"],\"HVAC System\"),\n",
    "               (EX[\"Lighting_System\"],\"Lighting System\"),\n",
    "               (EX[\"Weather_Station_1\"],\"Weather Station\")]\n",
    "    for s_uri, label in systems:\n",
    "        sid = short(s_uri); N(sid, label, \"system\"); c_sys.add_node(sid); E(\"Building\", sid, \"hasPart\")\n",
    "\n",
    "    # équipements\n",
    "    for e in g.subjects(None, BRICK.Equipment):\n",
    "        eid = short(e); N(eid, clean_label(eid), \"equip\"); c_eq.add_node(eid)\n",
    "        for sys_uri,_ in systems:\n",
    "            if (sys_uri, BRICK.hasPart, e) in g: E(short(sys_uri), eid, \"hasPart\")\n",
    "        E(eid, \"Room\", \"hasLocation\")\n",
    "\n",
    "    # capteurs TTL + dataset\n",
    "    for s,_,_ in g.triples((None, BF.hasTimeseriesId, None)):\n",
    "        sid = short(s); N(sid, clean_label(sid), \"sensor\"); c_sens.add_node(sid)\n",
    "        for sys_uri,_ in systems:\n",
    "            if (sys_uri, BRICK.hasPoint, s) in g or (sys_uri, BRICK.hasPart, s) in g:\n",
    "                E(short(sys_uri), sid, \"hasPoint\")\n",
    "        E(sid, \"Room\", \"hasLocation\",\"#999999\")\n",
    "\n",
    "        if sid in df.columns:\n",
    "            val, vmin, vmax, vmean = last_and_stats(df, sid)\n",
    "            oid = f\"obs_{sid}\"; N(oid, \"Observation\", \"obs\"); c_obs.add_node(oid); E(sid, oid, \"hasObservation\",\"#888888\")\n",
    "            vtext = f\"{val:.2f}\" if isinstance(val, (int,float)) and val is not None else str(df[sid].iloc[-1])\n",
    "            vid = f\"val_{sid}\"; N(vid, vtext, \"prop\"); c_obs.add_node(vid); E(oid, vid, \"hasSimpleResult\")\n",
    "            tid = f\"ts_{sid}\"\n",
    "            tslab = f\"TS (24h)\\\\nMin: {vmin:.2f}\\\\nMax: {vmax:.2f}\\\\nMean: {vmean:.2f}\" if None not in (vmin,vmax,vmean) else \"TS (24h) — n/a\"\n",
    "            G.add_node(tid, label=tslab, fontname=\"DejaVu Sans\", **STYLES[\"ts\"]); c_ts.add_node(tid); E(oid, tid, \"hasTimeSeries\",\"#999999\")\n",
    "\n",
    "    # météo virtuelle depuis dataset\n",
    "    weather_cols = {\n",
    "        \"Weather_Temp_Sensor\":\"Outdoor Temperature Sensor\",\n",
    "        \"Weather_RH_Sensor\":\"Outdoor Humidity Sensor\",\n",
    "        \"Weather_GHI_Sensor\":\"Solar Irradiance Sensor\",\n",
    "        \"Weather_Wind_Sensor\":\"Wind Speed Sensor\",\n",
    "    }\n",
    "    for col,label in weather_cols.items():\n",
    "        if col in df.columns:\n",
    "            nid = f\"virt_{col}\"; N(nid, label, \"virt\"); c_sens.add_node(nid); E(\"Site\", nid, \"hasSystem\")\n",
    "            val, vmin, vmax, vmean = last_and_stats(df, col)\n",
    "            oid = f\"obs_{nid}\"; N(oid, \"Observation\", \"obs\"); c_obs.add_node(oid); E(nid, oid, \"hasObservation\")\n",
    "            vtext = f\"{val:.2f}\" if isinstance(val,(int,float)) and val is not None else \"n/a\"\n",
    "            vid = f\"val_{nid}\"; N(vid, vtext, \"prop\"); c_obs.add_node(vid); E(oid, vid, \"hasSimpleResult\")\n",
    "            tid = f\"ts_{nid}\"\n",
    "            tslab = f\"TS (24h)\\\\nMin: {vmin:.2f}\\\\nMax: {vmax:.2f}\\\\nMean: {vmean:.2f}\" if None not in (vmin,vmax,vmean) else \"TS (24h) — n/a\"\n",
    "            G.add_node(tid, label=tslab, fontname=\"DejaVu Sans\", **STYLES[\"ts\"]); c_ts.add_node(tid); E(oid, tid, \"hasTimeSeries\")\n",
    "\n",
    "    # rendu\n",
    "    G.layout(prog=\"dot\")\n",
    "    svg_path = out_base.with_suffix(\".svg\")\n",
    "    png_path = out_base.with_suffix(\".png\")\n",
    "    G.draw(str(svg_path), format=\"svg\")\n",
    "    G.draw(str(png_path), format=\"png\")  # dpi déjà défini dans graph_attr\n",
    "    print(\"OK →\", svg_path)\n",
    "    print(\"OK →\", png_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259a5a4-2eac-4728-91d4-31c95588c645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
