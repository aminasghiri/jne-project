{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b312d9e-100c-4389-a1e0-d0b8eb054a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage of abort_on_error is deprecated. Use abort_on_first instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conformité globale: False\n",
      "Résumé violations par forme:\n",
      "                                   Shape  Violations\n",
      "0  n8f349bc08fd54642a3c4e4547637d038b11           1\n",
      "1  n8f349bc08fd54642a3c4e4547637d038b13           1\n",
      "2  n8f349bc08fd54642a3c4e4547637d038b15           1\n",
      "3   n8f349bc08fd54642a3c4e4547637d038b2           1\n",
      "4  n8f349bc08fd54642a3c4e4547637d038b21           1\n",
      "5  n8f349bc08fd54642a3c4e4547637d038b23           1\n",
      "6  n8f349bc08fd54642a3c4e4547637d038b27           1\n",
      "7   n8f349bc08fd54642a3c4e4547637d038b3           1\n",
      "8   n8f349bc08fd54642a3c4e4547637d038b5           1\n",
      "9   n8f349bc08fd54642a3c4e4547637d038b7           1\n",
      "Écrit: /home/amina/DTE/jne_project/graph/shacl_summary.csv et /home/amina/DTE/jne_project/graph/shacl_results.txt\n"
     ]
    }
   ],
   "source": [
    "# validate_shacl_and_summary.py\n",
    "from pathlib import Path\n",
    "from rdflib import Graph, Namespace\n",
    "from pyshacl import validate\n",
    "import pandas as pd\n",
    "\n",
    "# chemins\n",
    "BASE = Path.home()/ \"DTE\" / \"jne_project\"\n",
    "DATA_TTL   = BASE / \"graph\" / \"edtb_graph.ttl\"         # ton graphe\n",
    "SHAPES_TTL = BASE / \"graph\" / \"shapes.ttl\"             # le fichier ci-dessus\n",
    "OUT_CSV    = BASE / \"graph\" / \"shacl_summary.csv\"\n",
    "OUT_TEXT   = BASE / \"graph\" / \"shacl_results.txt\"\n",
    "\n",
    "# exécution\n",
    "data_g   = Graph().parse(DATA_TTL, format=\"turtle\")\n",
    "shapes_g = Graph().parse(SHAPES_TTL, format=\"turtle\")\n",
    "\n",
    "conforms, results_graph, results_text = validate(\n",
    "    data_graph=data_g,\n",
    "    shacl_graph=shapes_g,\n",
    "    inference='rdfs',\n",
    "    abort_on_error=False,\n",
    "    meta_shacl=False,\n",
    "    advanced=True,\n",
    ")\n",
    "\n",
    "# sauvegarde du rapport texte\n",
    "OUT_TEXT.write_text(results_text, encoding=\"utf-8\")\n",
    "\n",
    "# synthèse par forme (sourceShape)\n",
    "SH = Namespace(\"http://www.w3.org/ns/shacl#\")\n",
    "rows = []\n",
    "for r in results_graph.subjects(predicate=SH.resultSeverity):\n",
    "    src = results_graph.value(subject=r, predicate=SH.sourceShape)\n",
    "    msg = results_graph.value(subject=r, predicate=SH.resultMessage)\n",
    "    foc = results_graph.value(subject=r, predicate=SH.focusNode)\n",
    "    rows.append({\n",
    "        \"sourceShape\": str(src).split(\"#\")[-1] if src else \"\",\n",
    "        \"focusNode\":   str(foc).split(\"#\")[-1] if foc else \"\",\n",
    "        \"message\":     str(msg) if msg else \"\",\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    # conforme: construire un tableau vide avec 0 violation par forme définie\n",
    "    shapes = [str(s).split(\"#\")[-1] for s in shapes_g.subjects(RDF.type, SH.NodeShape)]\n",
    "    summary = pd.DataFrame({\"Shape\": shapes, \"Violations\": 0})\n",
    "else:\n",
    "    summary = df.groupby(\"sourceShape\", dropna=False).size().reset_index(name=\"Violations\")\n",
    "    summary.rename(columns={\"sourceShape\":\"Shape\"}, inplace=True)\n",
    "\n",
    "summary.sort_values(\"Violations\", ascending=False, inplace=True)\n",
    "summary.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"Conformité globale:\", conforms)\n",
    "print(\"Résumé violations par forme:\\n\", summary)\n",
    "print(\"Écrit:\", OUT_CSV, \"et\", OUT_TEXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74de7bad-6b72-4400-8448-3f5c6f862cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape  Nombre de violations       Exemple\n",
      "0  None                    10  [None, None]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "from pyshacl import validate\n",
    "\n",
    "# Charger graphe RDF\n",
    "graph_file = \"/home/amina/DTE/jne_project/graph/edtb_graph.ttl\"\n",
    "g = Graph().parse(graph_file, format=\"turtle\")\n",
    "\n",
    "# Charger les shapes SHACL\n",
    "shapes_file = \"/home/amina/DTE/jne_project/graph/shapes.ttl\"\n",
    "shapes_g = Graph().parse(shapes_file, format=\"turtle\")\n",
    "\n",
    "# Validation SHACL\n",
    "conforms, results_graph, results_text = validate(\n",
    "    g, shacl_graph=shapes_g,\n",
    "    ont_graph=None, inference='rdfs',\n",
    "    abort_on_first=False, meta_shacl=False, debug=False\n",
    ")\n",
    "\n",
    "# Extraire résultats\n",
    "violations = []\n",
    "for s, p, o in results_graph.triples((None, None, None)):\n",
    "    if str(p).endswith(\"resultMessage\"):\n",
    "        shape = results_graph.value(subject=s, predicate=results_graph.namespace_manager.qname(\"sh:sourceShape\"))\n",
    "        focus = results_graph.value(subject=s, predicate=results_graph.namespace_manager.qname(\"sh:focusNode\"))\n",
    "        violations.append({\n",
    "            \"Shape\": str(shape),\n",
    "            \"Violation\": str(o),\n",
    "            \"Exemple\": str(focus)\n",
    "        })\n",
    "\n",
    "# Construire tableau résumé\n",
    "df = pd.DataFrame(violations)\n",
    "summary = df.groupby(\"Shape\").agg({\n",
    "    \"Violation\": \"count\",\n",
    "    \"Exemple\": lambda x: list(x)[:2]  # max 2 exemples\n",
    "}).reset_index().rename(columns={\"Violation\": \"Nombre de violations\"})\n",
    "\n",
    "# Sauvegarde\n",
    "summary.to_csv(\"/home/amina/DTE/jne_project/graph/shacl_summary_detailed.csv\", index=False)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2c7c7a-5ce1-4b26-8378-f496fd0a7644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples total : 175715\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "g = Graph()\n",
    "g.parse(\"/home/amina/DTE/jne_project/graph/edtb_graph.ttl\", format=\"turtle\")\n",
    "print(\"Triples total :\", len(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc67919-9ecd-4da3-874a-e492e217e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples Brick : 58\n",
      "Triples EX    : 175715\n",
      "Triples total : 175715\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/amina/bim_only.ttl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m files \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIM only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbim_only.ttl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIM + Weather\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbim_weather.ttl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIM + Weather + IoT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbim_weather_iot.ttl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIM + Weather + IoT + BMS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medtb_graph.ttl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, path \u001b[38;5;129;01min\u001b[39;00m files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 21\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mturtle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m28s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(g)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/rdflib/graph.py:1518\u001b[0m, in \u001b[0;36mGraph.parse\u001b[0;34m(self, source, publicID, format, location, file, data, **args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1425\u001b[0m     source: Optional[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[1;32m   1434\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Graph:\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;124;03m    Parse an RDF source adding the resulting triples to the Graph.\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \n\u001b[1;32m   1516\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1518\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_input_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublicID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpublicID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mcontent_type\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/rdflib/parser.py:735\u001b[0m, in \u001b[0;36mcreate_input_source\u001b[0;34m(source, publicID, location, file, data, format)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    729\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m source \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     (\n\u001b[1;32m    731\u001b[0m         absolute_location,\n\u001b[1;32m    732\u001b[0m         auto_close,\n\u001b[1;32m    733\u001b[0m         file,\n\u001b[1;32m    734\u001b[0m         input_source,\n\u001b[0;32m--> 735\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_create_input_source_from_location\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/rdflib/parser.py:795\u001b[0m, in \u001b[0;36m_create_input_source_from_location\u001b[0;34m(file, format, input_source, location)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m absolute_location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:///\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    794\u001b[0m     filename \u001b[38;5;241m=\u001b[39m url2pathname(absolute_location\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:///\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 795\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m     input_source \u001b[38;5;241m=\u001b[39m URLInputSource(absolute_location, \u001b[38;5;28mformat\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/amina/bim_only.ttl'"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace\n",
    "g = Graph()\n",
    "g.parse(\"/home/amina/DTE/jne_project/graph/edtb_graph.ttl\", format=\"turtle\")\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/Brick#\")\n",
    "EX    = Namespace(\"http://example.org/training#\")\n",
    "\n",
    "def count_ns(ns):\n",
    "    return sum(1 for s,p,o in g if str(s).startswith(ns) or str(p).startswith(ns) or str(o).startswith(ns))\n",
    "\n",
    "print(\"Triples Brick :\", count_ns(str(BRICK)))\n",
    "print(\"Triples EX    :\", count_ns(str(EX)))\n",
    "print(\"Triples total :\", len(g))\n",
    "\n",
    "files = {\n",
    "    \"BIM only\": \"bim_only.ttl\",\n",
    "    \"BIM + Weather\": \"bim_weather.ttl\",\n",
    "    \"BIM + Weather + IoT\": \"bim_weather_iot.ttl\",\n",
    "    \"BIM + Weather + IoT + BMS\": \"edtb_graph.ttl\",\n",
    "}\n",
    "for label, path in files.items():\n",
    "    g = Graph().parse(path, format=\"turtle\")\n",
    "    print(f\"{label:28s} {len(g):d}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c9668b-5547-4ef0-9343-40c470e8ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples total : 175715\n",
      "≈Triples Brick : 58\n",
      "≈Triples EX    : 175715\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace\n",
    "BASE = Path.home()/\"DTE\"/\"jne_project\"/\"graph\"/\"edtb_graph.ttl\"\n",
    "g = Graph().parse(BASE.as_posix(), format=\"turtle\")\n",
    "print(\"Triples total :\", len(g))\n",
    "\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/Brick#\")\n",
    "EX    = Namespace(\"http://example.org/training#\")\n",
    "def count_ns(ns):\n",
    "    return sum(1 for s,p,o in g if str(s).startswith(ns) or str(p).startswith(ns) or str(o).startswith(ns))\n",
    "print(\"≈Triples Brick :\", count_ns(str(BRICK)))\n",
    "print(\"≈Triples EX    :\", count_ns(str(EX)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379b5c67-8327-4c6e-aff5-16a0fc84e8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples total: 175715\n",
      "Sujets uniques: 34568\n",
      "Prédicats uniques: 16\n",
      "Objets uniques: 16674\n",
      "Rooms: 1\n",
      "HVAC systems: 1\n",
      "Lighting systems: 1\n",
      "Weather stations: 1\n",
      "Temp sensors: 1\n",
      "Humidity sensors: 1\n",
      "CO2 sensors: 1\n",
      "Power sensors: 1\n",
      "Occupancy sensors: 2\n",
      "Observations SOSA: 34548\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace\n",
    "g = Graph().parse(\"/home/amina/DTE/jne_project/graph/edtb_graph.ttl\", format=\"turtle\")\n",
    "\n",
    "print(\"Triples total:\", len(g))\n",
    "print(\"Sujets uniques:\", len(set(s for s,_,_ in g)))\n",
    "print(\"Prédicats uniques:\", len(set(p for _,p,_ in g)))\n",
    "print(\"Objets uniques:\", len(set(o for _,_,o in g)))\n",
    "\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/Brick#\")\n",
    "SOS  = Namespace(\"http://www.w3.org/ns/sosa/\")\n",
    "\n",
    "def count_type(t):\n",
    "    return sum(1 for _ in g.triples((None, g.namespace_manager.qname(\"rdf:type\"), t)))  # si échec, SPARQL ci-dessous\n",
    "\n",
    "# plus robuste avec SPARQL:\n",
    "def ctype(turi):\n",
    "    return list(g.query(f\"SELECT (COUNT(*) AS ?n) WHERE {{ ?s a <{turi}> }}\"))[0][0]\n",
    "\n",
    "print(\"Rooms:\", ctype(BRICK.Room))\n",
    "print(\"HVAC systems:\", ctype(BRICK.HVAC_System))\n",
    "print(\"Lighting systems:\", ctype(BRICK.Lighting_System))\n",
    "print(\"Weather stations:\", ctype(BRICK.Weather_Station))\n",
    "\n",
    "print(\"Temp sensors:\", ctype(BRICK.Temperature_Sensor))\n",
    "print(\"Humidity sensors:\", ctype(BRICK.Humidity_Sensor))\n",
    "print(\"CO2 sensors:\", ctype(BRICK.CO2_Sensor))\n",
    "print(\"Power sensors:\", ctype(BRICK.Power_Sensor))\n",
    "print(\"Occupancy sensors:\", ctype(BRICK.Occupancy_Sensor))\n",
    "\n",
    "print(\"Observations SOSA:\", list(g.query(\n",
    "    \"SELECT (COUNT(*) AS ?n) WHERE { ?o a <http://www.w3.org/ns/sosa/Observation> }\"\n",
    "))[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f22a538-9292-42c2-8b5e-3f1a5d49c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Par source (approx.) ===\n",
      "Weather      | sensors:    0 | observations:      0 | obs_triples≈       0\n",
      "IoT (rooms)  | sensors:    0 | observations:      0 | obs_triples≈       0\n",
      "BMS          | sensors:    7 | observations:  20160 | obs_triples≈  100800\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from pathlib import Path\n",
    "\n",
    "TTL = Path.home()/\"DTE\"/\"jne_project\"/\"graph\"/\"edtb_graph.ttl\"\n",
    "g = Graph().parse(TTL.as_posix(), format=\"turtle\")\n",
    "\n",
    "BRICK = \"https://brickschema.org/schema/Brick#\"\n",
    "SOSA  = \"http://www.w3.org/ns/sosa/\"\n",
    "\n",
    "def q(qs):  # helper\n",
    "    return list(g.query(qs))\n",
    "\n",
    "def triples_for_subjects(S):\n",
    "    S = set(S)\n",
    "    return sum(1 for s,p,o in g if s in S)\n",
    "\n",
    "# --- groupes de capteurs ---\n",
    "room_sensors = {s for (s,) in q(f\"\"\"\n",
    "  SELECT ?s WHERE {{\n",
    "    ?s a <{BRICK}Sensor> ;\n",
    "       <{BRICK}isLocatedIn> ?r .\n",
    "    ?r a <{BRICK}Room> .\n",
    "  }}\n",
    "\"\"\")}\n",
    "\n",
    "weather_sensors = {s for (s,) in q(f\"\"\"\n",
    "  SELECT ?s WHERE {{\n",
    "    ?s a <{BRICK}Sensor> ;\n",
    "       <{BRICK}isLocatedIn> ?st .\n",
    "    ?st a <{BRICK}Weather_Station> .\n",
    "  }}\n",
    "\"\"\")}\n",
    "\n",
    "bms_sensors = {s for (s,) in q(f\"\"\"\n",
    "  SELECT ?s WHERE {{\n",
    "    ?sys <{BRICK}hasPoint> ?s ;\n",
    "         a <{BRICK}HVAC_System> .\n",
    "  }}\n",
    "\"\"\")} | {s for (s,) in q(f\"\"\"\n",
    "  SELECT ?s WHERE {{\n",
    "    ?sys <{BRICK}hasPoint> ?s ;\n",
    "         a <{BRICK}Lighting_System> .\n",
    "  }}\n",
    "\"\"\")}\n",
    "\n",
    "# observations liées à un ensemble de capteurs\n",
    "def obs_of(sensors):\n",
    "    sensors = list(sensors)\n",
    "    if not sensors:\n",
    "        return set()\n",
    "    values = \" \".join(f\"<{str(x)}>\" for x in sensors)\n",
    "    res = q(f\"\"\"\n",
    "      SELECT ?o WHERE {{\n",
    "        VALUES ?s {{ {values} }}\n",
    "        ?o a <{SOSA}Observation> ;\n",
    "           <{SOSA}madeBySensor> ?s .\n",
    "      }}\n",
    "    \"\"\")\n",
    "    return {r[0] for r in res}\n",
    "\n",
    "def summarize_group(name, sensors):\n",
    "    obs = obs_of(sensors)\n",
    "    t_obs = triples_for_subjects(obs)\n",
    "    print(f\"{name:12s} | sensors: {len(sensors):4d} | observations: {len(obs):6d} | obs_triples≈ {t_obs:7d}\")\n",
    "\n",
    "print(\"\\n=== Par source (approx.) ===\")\n",
    "summarize_group(\"Weather\",   weather_sensors)\n",
    "summarize_group(\"IoT (rooms)\", room_sensors)\n",
    "summarize_group(\"BMS\",       bms_sensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a328fd96-4936-488a-8ea9-ac3c4f0d2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> /home/amina/DTE/jne_project/graph/bim_only.ttl | triples: 95\n",
      "OK -> /home/amina/DTE/jne_project/graph/bim_weather.ttl | triples: 69151\n",
      "OK -> /home/amina/DTE/jne_project/graph/bim_weather_iot.ttl | triples: 155561\n",
      "OK -> /home/amina/DTE/jne_project/graph/edtb_graph.ttl | triples: 207410\n"
     ]
    }
   ],
   "source": [
    "# build_graph_stepwise.py\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "# ---------- Chemins ----------\n",
    "HOME = Path.home()\n",
    "BASE = HOME / \"DTE\" / \"jne_project\"\n",
    "GRAPH_DIR = BASE / \"graph\"\n",
    "RAW_DIR   = BASE / \"raw\"\n",
    "\n",
    "BIM_TTL = GRAPH_DIR / \"Training_room_en.ttl\"  # BIM de base (déjà fourni)\n",
    "\n",
    "OUT_BIM_ONLY         = GRAPH_DIR / \"bim_only.ttl\"\n",
    "OUT_BIM_WEATHER      = GRAPH_DIR / \"bim_weather.ttl\"\n",
    "OUT_BIM_WEATHER_IOT  = GRAPH_DIR / \"bim_weather_iot.ttl\"\n",
    "OUT_FINAL            = GRAPH_DIR / \"edtb_graph.ttl\"\n",
    "\n",
    "# ---------- Vocabulaires ----------\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/Brick#\")\n",
    "SOSA  = Namespace(\"http://www.w3.org/ns/sosa/\")\n",
    "QUDT  = Namespace(\"http://qudt.org/schema/qudt/\")\n",
    "UNIT  = Namespace(\"http://qudt.org/vocab/unit/\")\n",
    "EX    = Namespace(\"http://example.org/training#\")\n",
    "\n",
    "# ---------- Utilitaires ----------\n",
    "def bind_prefixes(g: Graph) -> Graph:\n",
    "    g.bind(\"brick\", BRICK); g.bind(\"sosa\", SOSA)\n",
    "    g.bind(\"qudt\", QUDT);   g.bind(\"unit\", UNIT)\n",
    "    g.bind(\"ex\", EX);       g.bind(\"rdfs\", RDFS)\n",
    "    return g\n",
    "\n",
    "def read_one_csv(path_or_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Accepte un fichier ou un dossier (avec 1 CSV).\"\"\"\n",
    "    p = path_or_dir\n",
    "    if p.is_dir():\n",
    "        csvs = sorted(p.glob(\"*.csv\"))\n",
    "        if len(csvs) != 1:\n",
    "            raise FileNotFoundError(f\"Attendu 1 CSV dans {p}, trouvé {len(csvs)}.\")\n",
    "        p = csvs[0]\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "def getcol(df: pd.DataFrame, alts: list[str]) -> str:\n",
    "    \"\"\"Retourne le nom de colonne existant parmi des alternatives.\"\"\"\n",
    "    for c in alts:\n",
    "        if c in df.columns: return c\n",
    "    raise KeyError(f\"Colonne manquante, alternatives: {alts}\")\n",
    "\n",
    "def add_obs(g: Graph, sensor: URIRef, when, value,\n",
    "            observed_property_iri: URIRef, unit_iri: URIRef):\n",
    "    \"\"\"Ajoute une observation SOSA simple (valeur + time + unité).\"\"\"\n",
    "    ts = pd.to_datetime(when, utc=True)\n",
    "    oid = URIRef(str(sensor) + f\"/obs/{ts.value}\")\n",
    "    g.add((oid, RDF.type, SOSA.Observation))\n",
    "    g.add((oid, SOSA.madeBySensor, sensor))\n",
    "    g.add((oid, SOSA.observedProperty, observed_property_iri))\n",
    "    g.add((oid, SOSA.hasSimpleResult, Literal(value)))\n",
    "    g.add((oid, QUDT.unit, unit_iri))\n",
    "    g.add((oid, SOSA.resultTime, Literal(ts.to_pydatetime(), datatype=XSD.dateTime)))\n",
    "\n",
    "# ---------- Étapes ----------\n",
    "def load_bim() -> Graph:\n",
    "    g = Graph().parse(BIM_TTL.as_posix(), format=\"turtle\")\n",
    "    return bind_prefixes(g)\n",
    "\n",
    "def add_weather(g: Graph, weather_csv: Path, sample_every: int | None = None):\n",
    "    df = read_one_csv(weather_csv).copy()\n",
    "    df[getcol(df, [\"ts\",\"time\",\"timestamp\"])] = pd.to_datetime(\n",
    "        df[getcol(df, [\"ts\",\"time\",\"timestamp\"])], utc=True)\n",
    "    df = df.rename(columns={\n",
    "        getcol(df, [\"ts\",\"time\",\"timestamp\"]): \"ts\",\n",
    "        getcol(df, [\"weather_temp_c\",\"T_ext\",\"temp_c\"]): \"T\",\n",
    "        getcol(df, [\"weather_rh_pct\",\"RH\",\"rh_pct\"]): \"RH\",\n",
    "        getcol(df, [\"weather_wind_ms\",\"wind\",\"wind_ms\"]): \"W\",\n",
    "        getcol(df, [\"weather_ghi_wm2\",\"GHI\",\"ghi_wm2\"]): \"GHI\",\n",
    "    })\n",
    "    st = EX.WeatherStation1\n",
    "    g.add((st, RDF.type, BRICK.Weather_Station))\n",
    "    sT = EX.WS_Temp; g.add((sT, RDF.type, BRICK.Temperature_Sensor)); g.add((sT, BRICK.isLocatedIn, st))\n",
    "    sH = EX.WS_RH;   g.add((sH, RDF.type, BRICK.Humidity_Sensor));    g.add((sH, BRICK.isLocatedIn, st))\n",
    "    sW = EX.WS_Wind; g.add((sW, RDF.type, BRICK.Wind_Speed_Sensor));  g.add((sW, BRICK.isLocatedIn, st))\n",
    "    sG = EX.WS_GHI;  g.add((sG, RDF.type, BRICK.Solar_Radiation_Sensor)); g.add((sG, BRICK.isLocatedIn, st))\n",
    "\n",
    "    step = sample_every or 1\n",
    "    for _, r in df.iloc[::step].iterrows():\n",
    "        ts = r[\"ts\"]\n",
    "        add_obs(g, sT, ts, r[\"T\"],  BRICK.Air_Temperature, UNIT[\"DegreeC\"])\n",
    "        add_obs(g, sH, ts, r[\"RH\"], BRICK.Relative_Humidity, UNIT[\"Percent\"])\n",
    "        add_obs(g, sW, ts, r[\"W\"],  BRICK.Wind_Speed, UNIT[\"MeterPerSecond\"])\n",
    "        add_obs(g, sG, ts, r[\"GHI\"],BRICK.Solar_Irradiance, UNIT[\"W-PER-M2\"])\n",
    "\n",
    "def add_iot(g: Graph, sensors_csv: Path, sample_every: int | None = None):\n",
    "    df = read_one_csv(sensors_csv).copy()\n",
    "    df[getcol(df, [\"ts\",\"time\",\"timestamp\"])] = pd.to_datetime(\n",
    "        df[getcol(df, [\"ts\",\"time\",\"timestamp\"])], utc=True)\n",
    "    df = df.rename(columns={\n",
    "        getcol(df, [\"ts\",\"time\",\"timestamp\"]): \"ts\",\n",
    "        getcol(df, [\"temp_int_c\",\"T_int\",\"room_temp_c\"]): \"T_int\",\n",
    "        getcol(df, [\"rh_int_pct\",\"RH_int\",\"room_rh_pct\"]): \"RH_int\",\n",
    "        getcol(df, [\"co2_ppm\",\"CO2\",\"co2\"]): \"CO2\",\n",
    "        getcol(df, [\"pir_bin\",\"PIR\",\"occupancy\"]): \"PIR\",\n",
    "        getcol(df, [\"power_total_kw\",\"P_total\",\"power_kw\"]): \"P_kw\",\n",
    "    })\n",
    "\n",
    "    room = EX.Room_101\n",
    "    sTi = EX.R101_Temp;  g.add((sTi, RDF.type, BRICK.Temperature_Sensor)); g.add((sTi, BRICK.isLocatedIn, room))\n",
    "    sRHi= EX.R101_RH;    g.add((sRHi, RDF.type, BRICK.Humidity_Sensor));   g.add((sRHi, BRICK.isLocatedIn, room))\n",
    "    sCO2= EX.R101_CO2;   g.add((sCO2, RDF.type, BRICK.CO2_Sensor));        g.add((sCO2, BRICK.isLocatedIn, room))\n",
    "    sPIR= EX.R101_PIR;   g.add((sPIR, RDF.type, BRICK.Occupancy_Sensor));  g.add((sPIR, BRICK.isLocatedIn, room))\n",
    "    sPow= EX.R101_Power; g.add((sPow, RDF.type, BRICK.Power_Sensor));      g.add((sPow, BRICK.isLocatedIn, room))\n",
    "\n",
    "    step = sample_every or 1\n",
    "    for _, r in df.iloc[::step].iterrows():\n",
    "        ts = r[\"ts\"]\n",
    "        add_obs(g, sTi, ts, r[\"T_int\"],  BRICK.Air_Temperature, UNIT[\"DegreeC\"])\n",
    "        add_obs(g, sRHi, ts, r[\"RH_int\"],BRICK.Relative_Humidity, UNIT[\"Percent\"])\n",
    "        add_obs(g, sCO2, ts, r[\"CO2\"],   BRICK.CO2, UNIT[\"PPM\"])\n",
    "        add_obs(g, sPIR, ts, int(r[\"PIR\"]), BRICK.Occupancy, UNIT[\"UNITLESS\"])\n",
    "        add_obs(g, sPow, ts, r[\"P_kw\"],  BRICK.Electric_Power, UNIT[\"KiloW\"])\n",
    "\n",
    "def add_bms(g: Graph, bms_csv: Path, sample_every: int | None = None):\n",
    "    df = read_one_csv(bms_csv).copy()\n",
    "    df[getcol(df, [\"ts\",\"time\",\"timestamp\"])] = pd.to_datetime(\n",
    "        df[getcol(df, [\"ts\",\"time\",\"timestamp\"])], utc=True)\n",
    "    df = df.rename(columns={\n",
    "        getcol(df, [\"ts\",\"time\",\"timestamp\"]): \"ts\",\n",
    "        getcol(df, [\"T_set\",\"setpoint_c\",\"set_temp_c\"]): \"T_set\",\n",
    "        getcol(df, [\"P_hvac\",\"hvac_kw\"]): \"P_hvac\",\n",
    "        getcol(df, [\"P_lighting\",\"lighting_kw\"]): \"P_light\",\n",
    "    })\n",
    "\n",
    "    room = EX.Room_101\n",
    "    hvac = EX.HVAC1;     g.add((hvac, RDF.type, BRICK.HVAC_System));     g.add((hvac, BRICK.feeds, room))\n",
    "    light= EX.Lighting1; g.add((light, RDF.type, BRICK.Lighting_System)); g.add((light, BRICK.feeds, room))\n",
    "\n",
    "    pH = EX.HVAC_Power;  g.add((pH, RDF.type, BRICK.Power_Sensor)); g.add((hvac,  BRICK.hasPoint, pH)); g.add((pH, BRICK.isLocatedIn, room))\n",
    "    pL = EX.Light_Power; g.add((pL, RDF.type, BRICK.Power_Sensor)); g.add((light, BRICK.hasPoint, pL)); g.add((pL, BRICK.isLocatedIn, room))\n",
    "    pSet = EX.HVAC_Tset; g.add((pSet, RDF.type, BRICK.Temperature_Sensor)); g.add((hvac, BRICK.hasPoint, pSet)); g.add((pSet, BRICK.isLocatedIn, room))\n",
    "\n",
    "    step = sample_every or 1\n",
    "    for _, r in df.iloc[::step].iterrows():\n",
    "        ts = r[\"ts\"]\n",
    "        if \"P_hvac\" in r:  add_obs(g, pH,   ts, r[\"P_hvac\"], BRICK.Electric_Power, UNIT[\"KiloW\"])\n",
    "        if \"P_light\" in r: add_obs(g, pL,   ts, r[\"P_light\"], BRICK.Electric_Power, UNIT[\"KiloW\"])\n",
    "        if \"T_set\"  in r:  add_obs(g, pSet, ts, r[\"T_set\"],  BRICK.Air_Temperature, UNIT[\"DegreeC\"])\n",
    "\n",
    "# ---------- Main ----------\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--month\", default=\"2025-03\", help=\"YYYY-MM sous raw/\")\n",
    "    ap.add_argument(\"--sample_every\", type=int, default=None, help=\"1 = tout, 4 = 1/4 des lignes\")\n",
    "    args, _ = ap.parse_known_args()   # OK pour Jupyter\n",
    "\n",
    "    WX  = RAW_DIR / \"weather\" / args.month / \"weather.csv\"\n",
    "    IOT = RAW_DIR / \"sensors\" / args.month / \"zone_101_sensors.csv\"\n",
    "    BMS = RAW_DIR / \"bms\"     / args.month / \"bms.csv\"\n",
    "    GRAPH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) BIM ONLY\n",
    "    g = load_bim()\n",
    "    g.serialize(OUT_BIM_ONLY.as_posix(), format=\"turtle\")\n",
    "    print(\"OK ->\", OUT_BIM_ONLY, \"| triples:\", len(g))\n",
    "\n",
    "    # 2) + WEATHER\n",
    "    add_weather(g, WX, sample_every=args.sample_every)\n",
    "    g.serialize(OUT_BIM_WEATHER.as_posix(), format=\"turtle\")\n",
    "    print(\"OK ->\", OUT_BIM_WEATHER, \"| triples:\", len(g))\n",
    "\n",
    "    # 3) + IoT\n",
    "    add_iot(g, IOT, sample_every=args.sample_every)\n",
    "    g.serialize(OUT_BIM_WEATHER_IOT.as_posix(), format=\"turtle\")\n",
    "    print(\"OK ->\", OUT_BIM_WEATHER_IOT, \"| triples:\", len(g))\n",
    "\n",
    "    # 4) + BMS (final)\n",
    "    add_bms(g, BMS, sample_every=args.sample_every)\n",
    "    g.serialize(OUT_FINAL.as_posix(), format=\"turtle\")\n",
    "    print(\"OK ->\", OUT_FINAL, \"| triples:\", len(g))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f43db-30aa-44bd-b5fe-e94d5db33614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
